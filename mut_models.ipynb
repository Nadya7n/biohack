{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:26.140880Z","iopub.execute_input":"2023-08-12T10:56:26.141236Z","iopub.status.idle":"2023-08-12T10:56:29.582961Z","shell.execute_reply.started":"2023-08-12T10:56:26.141211Z","shell.execute_reply":"2023-08-12T10:56:29.581914Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/hackaton/train_dataset.csv\", header=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:31.293124Z","iopub.execute_input":"2023-08-12T10:56:31.293623Z","iopub.status.idle":"2023-08-12T10:56:31.338268Z","shell.execute_reply.started":"2023-08-12T10:56:31.293596Z","shell.execute_reply":"2023-08-12T10:56:31.337265Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.columns = [\"wt\", \"mut\", \"score\", \"pos\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:32.363326Z","iopub.execute_input":"2023-08-12T10:56:32.363706Z","iopub.status.idle":"2023-08-12T10:56:32.370247Z","shell.execute_reply.started":"2023-08-12T10:56:32.363655Z","shell.execute_reply":"2023-08-12T10:56:32.368625Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install fair-esm","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:33.739150Z","iopub.execute_input":"2023-08-12T10:56:33.739567Z","iopub.status.idle":"2023-08-12T10:56:45.005884Z","shell.execute_reply.started":"2023-08-12T10:56:33.739535Z","shell.execute_reply":"2023-08-12T10:56:45.004904Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import esm","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:46.635454Z","iopub.execute_input":"2023-08-12T10:56:46.635820Z","iopub.status.idle":"2023-08-12T10:56:46.651467Z","shell.execute_reply.started":"2023-08-12T10:56:46.635793Z","shell.execute_reply":"2023-08-12T10:56:46.649604Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:50.270557Z","iopub.execute_input":"2023-08-12T10:56:50.271068Z","iopub.status.idle":"2023-08-12T10:56:50.277283Z","shell.execute_reply.started":"2023-08-12T10:56:50.271042Z","shell.execute_reply":"2023-08-12T10:56:50.275847Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nTRAIN_SIZE = 7000","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:51.331524Z","iopub.execute_input":"2023-08-12T10:56:51.331850Z","iopub.status.idle":"2023-08-12T10:56:51.336569Z","shell.execute_reply.started":"2023-08-12T10:56:51.331824Z","shell.execute_reply":"2023-08-12T10:56:51.335511Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = train.sample(frac=1.0, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:53.742491Z","iopub.execute_input":"2023-08-12T10:56:53.742864Z","iopub.status.idle":"2023-08-12T10:56:53.754684Z","shell.execute_reply.started":"2023-08-12T10:56:53.742834Z","shell.execute_reply":"2023-08-12T10:56:53.753002Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df = data.iloc[:TRAIN_SIZE, :]\nvalid_df = data.iloc[TRAIN_SIZE:, :]","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:56:59.639543Z","iopub.execute_input":"2023-08-12T10:56:59.639859Z","iopub.status.idle":"2023-08-12T10:56:59.645405Z","shell.execute_reply.started":"2023-08-12T10:56:59.639836Z","shell.execute_reply":"2023-08-12T10:56:59.644410Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df.index = np.arange(0, len(train_df))\nvalid_df.index = np.arange(0, len(valid_df))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:57:04.034073Z","iopub.execute_input":"2023-08-12T10:57:04.034943Z","iopub.status.idle":"2023-08-12T10:57:04.043325Z","shell.execute_reply.started":"2023-08-12T10:57:04.034913Z","shell.execute_reply":"2023-08-12T10:57:04.042155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Protseq(Dataset):\n    def __init__(self, df):\n        self.df = df\n        _, esm1v_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n        self.esm1v_batch_converter = esm1v_alphabet.get_batch_converter()\n\n        \n    def __getitem__(self, idx):\n        _, _, wt = self.esm1v_batch_converter([('' , ''.join(self.df.loc[idx, \"wt\"]))])\n        _, _, mut = self.esm1v_batch_converter([('' , ''.join(self.df.loc[idx, \"mut\"]))])\n        pos = self.df.loc[idx, \"pos\"]\n        target = torch.FloatTensor([self.df.loc[idx, \"score\"]])\n        return wt, mut, pos, target\n\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:57:13.636748Z","iopub.execute_input":"2023-08-12T10:57:13.637076Z","iopub.status.idle":"2023-08-12T10:57:13.644152Z","shell.execute_reply.started":"2023-08-12T10:57:13.637053Z","shell.execute_reply":"2023-08-12T10:57:13.643274Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:57:14.898985Z","iopub.execute_input":"2023-08-12T10:57:14.899590Z","iopub.status.idle":"2023-08-12T10:57:14.904042Z","shell.execute_reply.started":"2023-08-12T10:57:14.899563Z","shell.execute_reply":"2023-08-12T10:57:14.902651Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Protseq(train_df)\nvalid_ds = Protseq(valid_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:57:16.514587Z","iopub.execute_input":"2023-08-12T10:57:16.514951Z","iopub.status.idle":"2023-08-12T10:57:45.844558Z","shell.execute_reply.started":"2023-08-12T10:57:16.514926Z","shell.execute_reply":"2023-08-12T10:57:45.843845Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\nDownloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\nvalid_dataloader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:58:23.108086Z","iopub.execute_input":"2023-08-12T10:58:23.108831Z","iopub.status.idle":"2023-08-12T10:58:23.114763Z","shell.execute_reply.started":"2023-08-12T10:58:23.108805Z","shell.execute_reply":"2023-08-12T10:58:23.113146Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"HIDDEN_UNITS_POS_CONTACT = 5\nclass ESM_sum_sequence(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.esm2, _ = esm.pretrained.esm2_t33_650M_UR50D()\n        self.fc1 = nn.Linear(1280, HIDDEN_UNITS_POS_CONTACT)\n        self.fc2 = nn.Linear(HIDDEN_UNITS_POS_CONTACT, 1)\n    \n    \n    def _freeze_esm2_layers(self):\n        total_blocks = 33\n        initial_layers = 2\n        layers_per_block = 16\n        num_freeze_blocks = total_blocks - 3\n        for _, param in list(self.esm2.named_parameters())[\n            :initial_layers + layers_per_block * num_freeze_blocks]:\n            param.requires_grad = False\n            \n\n    def forward(self, token_ids1, token_ids2):\n        outputs1 = self.esm2.forward(token_ids1, repr_layers=[33])[\n            'representations'][33]\n        outputs2 = self.esm2.forward(token_ids2, repr_layers=[33])[\n            'representations'][33]\n        outputs1_mean = outputs1.mean(1)\n        outputs2_mean = outputs2.mean(1)\n        add = outputs1_mean + outputs2_mean\n        fc1_outputs = F.relu(self.fc1(add))\n        logits = self.fc2(fc1_outputs)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-08-12T10:22:07.221276Z","iopub.execute_input":"2023-08-12T10:22:07.221800Z","iopub.status.idle":"2023-08-12T10:22:07.233946Z","shell.execute_reply.started":"2023-08-12T10:22:07.221758Z","shell.execute_reply":"2023-08-12T10:22:07.232223Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"HIDDEN_UNITS_POS_CONTACT = 5\nclass ESM_concat_mut(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.esm2, _ = esm.pretrained.esm2_t33_650M_UR50D()\n        self.fc1 = nn.Linear(1280*2, HIDDEN_UNITS_POS_CONTACT)\n        self.fc2 = nn.Linear(HIDDEN_UNITS_POS_CONTACT, 1)\n    \n    \n    def _freeze_esm2_layers(self):\n        total_blocks = 33\n        initial_layers = 2\n        layers_per_block = 16\n        num_freeze_blocks = total_blocks - 3\n        for _, param in list(self.esm2.named_parameters())[\n            :initial_layers + layers_per_block * num_freeze_blocks]:\n            param.requires_grad = False\n            \n\n    def forward(self, wt_ids, mut_ids, pos):\n        outputs1 = self.esm2.forward(wt_ids, repr_layers=[33])[\n            'representations'][33]\n        outputs2 = self.esm2.forward(mut_ids, repr_layers=[33])[\n            'representations'][33]\n        wt_pos = outputs1[:, pos, :].squeeze(1)\n        mut_pos = outputs2[:, pos, :].squeeze(1)\n        pos_concat = torch.cat((wt_pos, mut_pos), 1)\n        fc1_outputs = F.relu(self.fc1(pos_concat))\n        logits = self.fc2(fc1_outputs)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:02:57.476723Z","iopub.execute_input":"2023-08-12T11:02:57.477114Z","iopub.status.idle":"2023-08-12T11:02:57.487402Z","shell.execute_reply.started":"2023-08-12T11:02:57.477079Z","shell.execute_reply":"2023-08-12T11:02:57.485408Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, model, epochs):\n    model.train()\n    for _ in range(epochs):\n        tr_loss = 0\n        for batch in tqdm(train_dataloader):\n            wt_ids, mut_ids, pos, labels = batch\n            wt_ids.squeeze_(1).to(device)\n            mut_ids.squeeze_(1).to(device)\n            labels = labels.to(device)\n            logits = model(wt_ids, mut_ids, pos)\n            loss = torch.nn.functional.mse_loss(logits, labels)\n            tr_loss += loss.item()\n        \n            torch.nn.utils.clip_grad_norm_(\n            parameters=model.parameters(), max_norm=0.1\n            )\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        epoch_loss = tr_loss / nb_tr_steps\n        print(f\"Training loss epoch: {epoch_loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:03:01.158243Z","iopub.execute_input":"2023-08-12T11:03:01.158589Z","iopub.status.idle":"2023-08-12T11:03:01.166746Z","shell.execute_reply.started":"2023-08-12T11:03:01.158565Z","shell.execute_reply":"2023-08-12T11:03:01.165552Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"lr = 1e-5\nEPOCHS = 3","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:03:04.200313Z","iopub.execute_input":"2023-08-12T11:03:04.201000Z","iopub.status.idle":"2023-08-12T11:03:04.207221Z","shell.execute_reply.started":"2023-08-12T11:03:04.200962Z","shell.execute_reply":"2023-08-12T11:03:04.205443Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = ESM_concat_mut().to(device)\noptimizer = torch.optim.Adam(params=model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:03:14.136516Z","iopub.execute_input":"2023-08-12T11:03:14.136909Z","iopub.status.idle":"2023-08-12T11:03:56.553784Z","shell.execute_reply.started":"2023-08-12T11:03:14.136881Z","shell.execute_reply":"2023-08-12T11:03:56.552016Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:03:59.643007Z","iopub.execute_input":"2023-08-12T11:03:59.643360Z","iopub.status.idle":"2023-08-12T11:03:59.653445Z","shell.execute_reply.started":"2023-08-12T11:03:59.643333Z","shell.execute_reply":"2023-08-12T11:03:59.651923Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"ESM_concat_mut(\n  (esm2): ESM2(\n    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n    (layers): ModuleList(\n      (0-32): 33 x TransformerLayer(\n        (self_attn): MultiheadAttention(\n          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n          (rot_emb): RotaryEmbedding()\n        )\n        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (contact_head): ContactPredictionHead(\n      (regression): Linear(in_features=660, out_features=1, bias=True)\n      (activation): Sigmoid()\n    )\n    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    (lm_head): RobertaLMHead(\n      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (fc1): Linear(in_features=2560, out_features=5, bias=True)\n  (fc2): Linear(in_features=5, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"train(train_dataloader, model, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T11:04:02.895852Z","iopub.execute_input":"2023-08-12T11:04:02.896164Z","iopub.status.idle":"2023-08-12T11:04:26.749583Z","shell.execute_reply.started":"2023-08-12T11:04:02.896142Z","shell.execute_reply":"2023-08-12T11:04:26.747709Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"  0%|          | 2/7000 [00:23<23:00:31, 11.84s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, model, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m     15\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m nb_tr_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}